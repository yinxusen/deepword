---
# for the legacy CNN DRRN

model_creator: CnnZorkDSQN
num_tokens: 1000
num_turns: 10
batch_size: 32
save_gap_t: 10000
embedding_size: 64
learning_rate: 1e-5
num_conv_filters: 32
tokenizer_type: NLTK
max_snapshot_to_keep: 10
eval_episode: 2
game_episode_terminal_t: 1800  # the actual steps are 600. we need extra two steps - look and inventory - to get state
replay_mem: 500000
collect_floor_plan: False
annealing_eps_t: 2000000
observation_t: 50000
n_actions: 130
init_eps: 1.0
final_eps: 1e-4
start_t_ignore_model_t: False  # set to False unless do curriculum learning
use_step_wise_reward: True
agent_clazz: DSQNZorkAgent  # original model uses CompetitionAgent
