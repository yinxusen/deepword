
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>deeptextworld.tokenizers &#8212; deep-textworld v4.0 documentation</title>
    <link rel="stylesheet" href="../../_static/alabaster.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <script id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/language_data.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
   
  <link rel="stylesheet" href="../../_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <h1>Source code for deeptextworld.tokenizers</h1><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">string</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="k">import</span> <span class="n">List</span><span class="p">,</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">Tuple</span>

<span class="kn">from</span> <span class="nn">albert.tokenization</span> <span class="k">import</span> <span class="n">FullTokenizer</span> <span class="k">as</span> <span class="n">AlbertTok</span>
<span class="kn">from</span> <span class="nn">bert.tokenization</span> <span class="k">import</span> <span class="n">FullTokenizer</span> <span class="k">as</span> <span class="n">BertTok</span>
<span class="kn">from</span> <span class="nn">nltk</span> <span class="k">import</span> <span class="n">word_tokenize</span>
<span class="kn">from</span> <span class="nn">tensorflow.contrib.training</span> <span class="k">import</span> <span class="n">HParams</span>

<span class="kn">from</span> <span class="nn">deeptextworld.hparams</span> <span class="k">import</span> <span class="n">conventions</span>
<span class="kn">from</span> <span class="nn">deeptextworld.hparams</span> <span class="k">import</span> <span class="n">copy_hparams</span>
<span class="kn">from</span> <span class="nn">deeptextworld.utils</span> <span class="k">import</span> <span class="n">load_vocab</span><span class="p">,</span> <span class="n">get_token2idx</span>


<div class="viewcode-block" id="Tokenizer"><a class="viewcode-back" href="../../deeptextworld.html#deeptextworld.tokenizers.Tokenizer">[docs]</a><span class="k">class</span> <span class="nc">Tokenizer</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">vocab</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">int</span><span class="p">]:</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">inv_vocab</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">str</span><span class="p">]:</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span>

<div class="viewcode-block" id="Tokenizer.tokenize"><a class="viewcode-back" href="../../deeptextworld.html#deeptextworld.tokenizers.Tokenizer.tokenize">[docs]</a>    <span class="k">def</span> <span class="nf">tokenize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">text</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span></div>

<div class="viewcode-block" id="Tokenizer.de_tokenize"><a class="viewcode-back" href="../../deeptextworld.html#deeptextworld.tokenizers.Tokenizer.de_tokenize">[docs]</a>    <span class="k">def</span> <span class="nf">de_tokenize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ids</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span></div>

<div class="viewcode-block" id="Tokenizer.convert_tokens_to_ids"><a class="viewcode-back" href="../../deeptextworld.html#deeptextworld.tokenizers.Tokenizer.convert_tokens_to_ids">[docs]</a>    <span class="k">def</span> <span class="nf">convert_tokens_to_ids</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tokens</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]:</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span></div>

<div class="viewcode-block" id="Tokenizer.convert_ids_to_tokens"><a class="viewcode-back" href="../../deeptextworld.html#deeptextworld.tokenizers.Tokenizer.convert_ids_to_tokens">[docs]</a>    <span class="k">def</span> <span class="nf">convert_ids_to_tokens</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ids</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span></div></div>


<div class="viewcode-block" id="NLTKTokenizer"><a class="viewcode-back" href="../../deeptextworld.html#deeptextworld.tokenizers.NLTKTokenizer">[docs]</a><span class="k">class</span> <span class="nc">NLTKTokenizer</span><span class="p">(</span><span class="n">Tokenizer</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Vocab is token2idx, inv_vocab is idx2token</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vocab_file</span><span class="p">,</span> <span class="n">do_lower_case</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_special_tokens</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">conventions</span><span class="o">.</span><span class="n">nltk_unk_token</span><span class="p">,</span>
            <span class="n">conventions</span><span class="o">.</span><span class="n">nltk_padding_token</span><span class="p">,</span>
            <span class="n">conventions</span><span class="o">.</span><span class="n">nltk_sos_token</span><span class="p">,</span>
            <span class="n">conventions</span><span class="o">.</span><span class="n">nltk_eos_token</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_inv_vocab</span> <span class="o">=</span> <span class="n">load_vocab</span><span class="p">(</span><span class="n">vocab_file</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">do_lower_case</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_inv_vocab</span> <span class="o">=</span> <span class="p">[</span>
                <span class="n">w</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="k">if</span> <span class="n">w</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_special_tokens</span> <span class="k">else</span> <span class="n">w</span>
                <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_inv_vocab</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_do_lower_case</span> <span class="o">=</span> <span class="n">do_lower_case</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_vocab</span> <span class="o">=</span> <span class="n">get_token2idx</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_inv_vocab</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_inv_vocab</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">([(</span><span class="n">v</span><span class="p">,</span> <span class="n">k</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_vocab</span><span class="o">.</span><span class="n">items</span><span class="p">()])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_unk_val_id</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_vocab</span><span class="p">[</span><span class="n">conventions</span><span class="o">.</span><span class="n">nltk_unk_token</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_s2c</span> <span class="o">=</span> <span class="p">{</span>
            <span class="n">conventions</span><span class="o">.</span><span class="n">nltk_unk_token</span><span class="p">:</span> <span class="s2">&quot;U&quot;</span><span class="p">,</span>
            <span class="n">conventions</span><span class="o">.</span><span class="n">nltk_padding_token</span><span class="p">:</span> <span class="s2">&quot;O&quot;</span><span class="p">,</span>
            <span class="n">conventions</span><span class="o">.</span><span class="n">nltk_sos_token</span><span class="p">:</span> <span class="s2">&quot;S&quot;</span><span class="p">,</span>
            <span class="n">conventions</span><span class="o">.</span><span class="n">nltk_eos_token</span><span class="p">:</span> <span class="s2">&quot;E&quot;</span><span class="p">}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_c2s</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_s2c</span><span class="o">.</span><span class="n">values</span><span class="p">(),</span> <span class="bp">self</span><span class="o">.</span><span class="n">_s2c</span><span class="o">.</span><span class="n">keys</span><span class="p">()))</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">vocab</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_vocab</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">inv_vocab</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_inv_vocab</span>

<div class="viewcode-block" id="NLTKTokenizer.convert_tokens_to_ids"><a class="viewcode-back" href="../../deeptextworld.html#deeptextworld.tokenizers.NLTKTokenizer.convert_tokens_to_ids">[docs]</a>    <span class="k">def</span> <span class="nf">convert_tokens_to_ids</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tokens</span><span class="p">):</span>
        <span class="n">indexed</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_vocab</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_unk_val_id</span><span class="p">)</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">tokens</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">indexed</span></div>

<div class="viewcode-block" id="NLTKTokenizer.convert_ids_to_tokens"><a class="viewcode-back" href="../../deeptextworld.html#deeptextworld.tokenizers.NLTKTokenizer.convert_ids_to_tokens">[docs]</a>    <span class="k">def</span> <span class="nf">convert_ids_to_tokens</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ids</span><span class="p">):</span>
        <span class="n">tokens</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_inv_vocab</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">ids</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">tokens</span></div>

<div class="viewcode-block" id="NLTKTokenizer.tokenize"><a class="viewcode-back" href="../../deeptextworld.html#deeptextworld.tokenizers.NLTKTokenizer.tokenize">[docs]</a>    <span class="k">def</span> <span class="nf">tokenize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">text</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">any</span><span class="p">([</span><span class="n">sc</span> <span class="ow">in</span> <span class="n">text</span> <span class="k">for</span> <span class="n">sc</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_special_tokens</span><span class="p">]):</span>
            <span class="n">new_txt</span> <span class="o">=</span> <span class="n">text</span>
            <span class="k">for</span> <span class="n">sc</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_special_tokens</span><span class="p">:</span>
                <span class="n">new_txt</span> <span class="o">=</span> <span class="n">new_txt</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="n">sc</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_s2c</span><span class="p">[</span><span class="n">sc</span><span class="p">])</span>
            <span class="n">tokens</span> <span class="o">=</span> <span class="n">word_tokenize</span><span class="p">(</span><span class="n">new_txt</span><span class="p">)</span>
            <span class="n">tokens</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_c2s</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="k">if</span> <span class="n">t</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_c2s</span> <span class="k">else</span> <span class="n">t</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">tokens</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">tokens</span> <span class="o">=</span> <span class="n">word_tokenize</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_do_lower_case</span><span class="p">:</span>
            <span class="k">return</span> <span class="p">[</span>
                <span class="n">t</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="k">if</span> <span class="n">t</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_special_tokens</span> <span class="k">else</span> <span class="n">t</span>
                <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">tokens</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">tokens</span></div>

<div class="viewcode-block" id="NLTKTokenizer.de_tokenize"><a class="viewcode-back" href="../../deeptextworld.html#deeptextworld.tokenizers.NLTKTokenizer.de_tokenize">[docs]</a>    <span class="k">def</span> <span class="nf">de_tokenize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ids</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="n">res</span> <span class="o">=</span> <span class="s2">&quot; &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span>
            <span class="nb">filter</span><span class="p">(</span><span class="k">lambda</span> <span class="n">t</span><span class="p">:</span> <span class="n">t</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_special_tokens</span><span class="p">,</span>
                   <span class="bp">self</span><span class="o">.</span><span class="n">convert_ids_to_tokens</span><span class="p">(</span><span class="n">ids</span><span class="p">)))</span>
        <span class="k">return</span> <span class="n">res</span></div></div>


<div class="viewcode-block" id="LegacyZorkTokenizer"><a class="viewcode-back" href="../../deeptextworld.html#deeptextworld.tokenizers.LegacyZorkTokenizer">[docs]</a><span class="k">class</span> <span class="nc">LegacyZorkTokenizer</span><span class="p">(</span><span class="n">NLTKTokenizer</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vocab_file</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">LegacyZorkTokenizer</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">vocab_file</span><span class="p">,</span> <span class="n">do_lower_case</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">empty_trans_table</span> <span class="o">=</span> <span class="nb">str</span><span class="o">.</span><span class="n">maketrans</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="n">string</span><span class="o">.</span><span class="n">punctuation</span><span class="p">)</span>

<div class="viewcode-block" id="LegacyZorkTokenizer.tokenize"><a class="viewcode-back" href="../../deeptextworld.html#deeptextworld.tokenizers.LegacyZorkTokenizer.tokenize">[docs]</a>    <span class="k">def</span> <span class="nf">tokenize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">text</span><span class="p">):</span>
        <span class="n">tokens</span> <span class="o">=</span> <span class="nb">super</span><span class="p">(</span><span class="n">LegacyZorkTokenizer</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span>
            <span class="n">text</span><span class="o">.</span><span class="n">translate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">empty_trans_table</span><span class="p">))</span>
        <span class="k">return</span> <span class="nb">list</span><span class="p">(</span><span class="nb">filter</span><span class="p">(</span><span class="k">lambda</span> <span class="n">t</span><span class="p">:</span> <span class="n">t</span><span class="o">.</span><span class="n">isalpha</span><span class="p">(),</span> <span class="n">tokens</span><span class="p">))</span></div></div>


<div class="viewcode-block" id="BertTokenizer"><a class="viewcode-back" href="../../deeptextworld.html#deeptextworld.tokenizers.BertTokenizer">[docs]</a><span class="k">class</span> <span class="nc">BertTokenizer</span><span class="p">(</span><span class="n">Tokenizer</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vocab_file</span><span class="p">,</span> <span class="n">do_lower_case</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">BertTok</span><span class="p">(</span><span class="n">vocab_file</span><span class="p">,</span> <span class="n">do_lower_case</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_special_tokens</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">conventions</span><span class="o">.</span><span class="n">bert_unk_token</span><span class="p">,</span>
            <span class="n">conventions</span><span class="o">.</span><span class="n">bert_padding_token</span><span class="p">,</span>
            <span class="n">conventions</span><span class="o">.</span><span class="n">bert_cls_token</span><span class="p">,</span>
            <span class="n">conventions</span><span class="o">.</span><span class="n">bert_sep_token</span><span class="p">,</span>
            <span class="n">conventions</span><span class="o">.</span><span class="n">bert_mask_token</span><span class="p">,</span>
            <span class="n">conventions</span><span class="o">.</span><span class="n">bert_sos_token</span><span class="p">,</span>
            <span class="n">conventions</span><span class="o">.</span><span class="n">bert_eos_token</span><span class="p">]</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">vocab</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">vocab</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">inv_vocab</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">inv_vocab</span>

<div class="viewcode-block" id="BertTokenizer.convert_tokens_to_ids"><a class="viewcode-back" href="../../deeptextworld.html#deeptextworld.tokenizers.BertTokenizer.convert_tokens_to_ids">[docs]</a>    <span class="k">def</span> <span class="nf">convert_tokens_to_ids</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tokens</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">convert_tokens_to_ids</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span></div>

<div class="viewcode-block" id="BertTokenizer.convert_ids_to_tokens"><a class="viewcode-back" href="../../deeptextworld.html#deeptextworld.tokenizers.BertTokenizer.convert_ids_to_tokens">[docs]</a>    <span class="k">def</span> <span class="nf">convert_ids_to_tokens</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ids</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">convert_ids_to_tokens</span><span class="p">(</span><span class="n">ids</span><span class="p">)</span></div>

<div class="viewcode-block" id="BertTokenizer.de_tokenize"><a class="viewcode-back" href="../../deeptextworld.html#deeptextworld.tokenizers.BertTokenizer.de_tokenize">[docs]</a>    <span class="k">def</span> <span class="nf">de_tokenize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ids</span><span class="p">):</span>
        <span class="n">res</span> <span class="o">=</span> <span class="s2">&quot; &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span>
            <span class="nb">filter</span><span class="p">(</span><span class="k">lambda</span> <span class="n">t</span><span class="p">:</span> <span class="n">t</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_special_tokens</span><span class="p">,</span>
                   <span class="bp">self</span><span class="o">.</span><span class="n">convert_ids_to_tokens</span><span class="p">(</span><span class="n">ids</span><span class="p">)))</span>
        <span class="n">res</span> <span class="o">=</span> <span class="n">res</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot; ##&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">res</span></div>

<div class="viewcode-block" id="BertTokenizer.tokenize"><a class="viewcode-back" href="../../deeptextworld.html#deeptextworld.tokenizers.BertTokenizer.tokenize">[docs]</a>    <span class="k">def</span> <span class="nf">tokenize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">text</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">text</span><span class="p">)</span></div></div>


<div class="viewcode-block" id="AlbertTokenizer"><a class="viewcode-back" href="../../deeptextworld.html#deeptextworld.tokenizers.AlbertTokenizer">[docs]</a><span class="k">class</span> <span class="nc">AlbertTokenizer</span><span class="p">(</span><span class="n">BertTokenizer</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vocab_file</span><span class="p">,</span> <span class="n">do_lower_case</span><span class="p">,</span> <span class="n">spm_model_file</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">AlbertTokenizer</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">vocab_file</span><span class="p">,</span> <span class="n">do_lower_case</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AlbertTok</span><span class="p">(</span><span class="n">vocab_file</span><span class="p">,</span> <span class="n">do_lower_case</span><span class="p">,</span> <span class="n">spm_model_file</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_special_tokens</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">conventions</span><span class="o">.</span><span class="n">albert_unk_token</span><span class="p">,</span>
            <span class="n">conventions</span><span class="o">.</span><span class="n">albert_padding_token</span><span class="p">,</span>
            <span class="n">conventions</span><span class="o">.</span><span class="n">albert_cls_token</span><span class="p">,</span>
            <span class="n">conventions</span><span class="o">.</span><span class="n">albert_sep_token</span><span class="p">,</span>
            <span class="n">conventions</span><span class="o">.</span><span class="n">albert_mask_token</span><span class="p">]</span>

<div class="viewcode-block" id="AlbertTokenizer.de_tokenize"><a class="viewcode-back" href="../../deeptextworld.html#deeptextworld.tokenizers.AlbertTokenizer.de_tokenize">[docs]</a>    <span class="k">def</span> <span class="nf">de_tokenize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ids</span><span class="p">):</span>
        <span class="n">res</span> <span class="o">=</span> <span class="s2">&quot; &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span>
            <span class="nb">filter</span><span class="p">(</span><span class="k">lambda</span> <span class="n">t</span><span class="p">:</span> <span class="n">t</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_special_tokens</span><span class="p">,</span>
                   <span class="bp">self</span><span class="o">.</span><span class="n">convert_ids_to_tokens</span><span class="p">(</span><span class="n">ids</span><span class="p">)))</span>
        <span class="n">res</span> <span class="o">=</span> <span class="n">res</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="sa">u</span><span class="s2">&quot;</span><span class="se">\u2581</span><span class="s2">&quot;</span><span class="p">,</span> <span class="s2">&quot; &quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">res</span></div></div>


<div class="viewcode-block" id="get_bert_tokenizer"><a class="viewcode-back" href="../../deeptextworld.html#deeptextworld.tokenizers.get_bert_tokenizer">[docs]</a><span class="k">def</span> <span class="nf">get_bert_tokenizer</span><span class="p">(</span><span class="n">hp</span><span class="p">:</span> <span class="n">HParams</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">HParams</span><span class="p">,</span> <span class="n">Tokenizer</span><span class="p">]:</span>
    <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">BertTokenizer</span><span class="p">(</span>
        <span class="n">vocab_file</span><span class="o">=</span><span class="n">conventions</span><span class="o">.</span><span class="n">bert_vocab_file</span><span class="p">,</span> <span class="n">do_lower_case</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">new_hp</span> <span class="o">=</span> <span class="n">copy_hparams</span><span class="p">(</span><span class="n">hp</span><span class="p">)</span>
    <span class="c1"># set vocab info</span>
    <span class="n">new_hp</span><span class="o">.</span><span class="n">set_hparam</span><span class="p">(</span><span class="s1">&#39;vocab_size&#39;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">vocab</span><span class="p">))</span>
    <span class="n">new_hp</span><span class="o">.</span><span class="n">set_hparam</span><span class="p">(</span><span class="s2">&quot;padding_val&quot;</span><span class="p">,</span> <span class="n">conventions</span><span class="o">.</span><span class="n">bert_padding_token</span><span class="p">)</span>
    <span class="n">new_hp</span><span class="o">.</span><span class="n">set_hparam</span><span class="p">(</span><span class="s2">&quot;unk_val&quot;</span><span class="p">,</span> <span class="n">conventions</span><span class="o">.</span><span class="n">bert_unk_token</span><span class="p">)</span>
    <span class="n">new_hp</span><span class="o">.</span><span class="n">set_hparam</span><span class="p">(</span><span class="s2">&quot;cls_val&quot;</span><span class="p">,</span> <span class="n">conventions</span><span class="o">.</span><span class="n">bert_cls_token</span><span class="p">)</span>
    <span class="n">new_hp</span><span class="o">.</span><span class="n">set_hparam</span><span class="p">(</span><span class="s2">&quot;sep_val&quot;</span><span class="p">,</span> <span class="n">conventions</span><span class="o">.</span><span class="n">bert_sep_token</span><span class="p">)</span>
    <span class="n">new_hp</span><span class="o">.</span><span class="n">set_hparam</span><span class="p">(</span><span class="s2">&quot;mask_val&quot;</span><span class="p">,</span> <span class="n">conventions</span><span class="o">.</span><span class="n">bert_mask_token</span><span class="p">)</span>
    <span class="n">new_hp</span><span class="o">.</span><span class="n">set_hparam</span><span class="p">(</span><span class="s2">&quot;sos&quot;</span><span class="p">,</span> <span class="n">conventions</span><span class="o">.</span><span class="n">bert_sos_token</span><span class="p">)</span>
    <span class="n">new_hp</span><span class="o">.</span><span class="n">set_hparam</span><span class="p">(</span><span class="s2">&quot;eos&quot;</span><span class="p">,</span> <span class="n">conventions</span><span class="o">.</span><span class="n">bert_eos_token</span><span class="p">)</span>

    <span class="c1"># set special token ids</span>
    <span class="n">new_hp</span><span class="o">.</span><span class="n">set_hparam</span><span class="p">(</span>
        <span class="s1">&#39;padding_val_id&#39;</span><span class="p">,</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">vocab</span><span class="p">[</span><span class="n">conventions</span><span class="o">.</span><span class="n">bert_padding_token</span><span class="p">])</span>
    <span class="k">assert</span> <span class="n">new_hp</span><span class="o">.</span><span class="n">padding_val_id</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;padding should be indexed as 0&quot;</span>
    <span class="n">new_hp</span><span class="o">.</span><span class="n">set_hparam</span><span class="p">(</span>
        <span class="s1">&#39;unk_val_id&#39;</span><span class="p">,</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">vocab</span><span class="p">[</span><span class="n">conventions</span><span class="o">.</span><span class="n">bert_unk_token</span><span class="p">])</span>
    <span class="c1"># bert specific tokens</span>
    <span class="n">new_hp</span><span class="o">.</span><span class="n">set_hparam</span><span class="p">(</span>
        <span class="s1">&#39;cls_val_id&#39;</span><span class="p">,</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">vocab</span><span class="p">[</span><span class="n">conventions</span><span class="o">.</span><span class="n">bert_cls_token</span><span class="p">])</span>
    <span class="n">new_hp</span><span class="o">.</span><span class="n">set_hparam</span><span class="p">(</span>
        <span class="s1">&#39;sep_val_id&#39;</span><span class="p">,</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">vocab</span><span class="p">[</span><span class="n">conventions</span><span class="o">.</span><span class="n">bert_sep_token</span><span class="p">])</span>
    <span class="n">new_hp</span><span class="o">.</span><span class="n">set_hparam</span><span class="p">(</span>
        <span class="s1">&#39;mask_val_id&#39;</span><span class="p">,</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">vocab</span><span class="p">[</span><span class="n">conventions</span><span class="o">.</span><span class="n">bert_mask_token</span><span class="p">])</span>
    <span class="n">new_hp</span><span class="o">.</span><span class="n">set_hparam</span><span class="p">(</span>
        <span class="s2">&quot;sos_id&quot;</span><span class="p">,</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">vocab</span><span class="p">[</span><span class="n">conventions</span><span class="o">.</span><span class="n">bert_sos_token</span><span class="p">])</span>
    <span class="n">new_hp</span><span class="o">.</span><span class="n">set_hparam</span><span class="p">(</span>
        <span class="s2">&quot;eos_id&quot;</span><span class="p">,</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">vocab</span><span class="p">[</span><span class="n">conventions</span><span class="o">.</span><span class="n">bert_eos_token</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">new_hp</span><span class="p">,</span> <span class="n">tokenizer</span></div>


<div class="viewcode-block" id="get_albert_tokenizer"><a class="viewcode-back" href="../../deeptextworld.html#deeptextworld.tokenizers.get_albert_tokenizer">[docs]</a><span class="k">def</span> <span class="nf">get_albert_tokenizer</span><span class="p">(</span><span class="n">hp</span><span class="p">:</span> <span class="n">HParams</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">HParams</span><span class="p">,</span> <span class="n">Tokenizer</span><span class="p">]:</span>
    <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AlbertTokenizer</span><span class="p">(</span>
        <span class="n">vocab_file</span><span class="o">=</span><span class="n">conventions</span><span class="o">.</span><span class="n">albert_vocab_file</span><span class="p">,</span>
        <span class="n">do_lower_case</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">spm_model_file</span><span class="o">=</span><span class="n">conventions</span><span class="o">.</span><span class="n">albert_spm_path</span><span class="p">)</span>
    <span class="n">new_hp</span> <span class="o">=</span> <span class="n">copy_hparams</span><span class="p">(</span><span class="n">hp</span><span class="p">)</span>
    <span class="c1"># make sure that padding_val is indexed as 0.</span>
    <span class="n">new_hp</span><span class="o">.</span><span class="n">set_hparam</span><span class="p">(</span><span class="s1">&#39;vocab_size&#39;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">vocab</span><span class="p">))</span>
    <span class="n">new_hp</span><span class="o">.</span><span class="n">set_hparam</span><span class="p">(</span><span class="s2">&quot;padding_val&quot;</span><span class="p">,</span> <span class="n">conventions</span><span class="o">.</span><span class="n">albert_padding_token</span><span class="p">)</span>
    <span class="n">new_hp</span><span class="o">.</span><span class="n">set_hparam</span><span class="p">(</span><span class="s2">&quot;unk_val&quot;</span><span class="p">,</span> <span class="n">conventions</span><span class="o">.</span><span class="n">albert_unk_token</span><span class="p">)</span>
    <span class="n">new_hp</span><span class="o">.</span><span class="n">set_hparam</span><span class="p">(</span><span class="s2">&quot;cls_val&quot;</span><span class="p">,</span> <span class="n">conventions</span><span class="o">.</span><span class="n">albert_cls_token</span><span class="p">)</span>
    <span class="n">new_hp</span><span class="o">.</span><span class="n">set_hparam</span><span class="p">(</span><span class="s2">&quot;sep_val&quot;</span><span class="p">,</span> <span class="n">conventions</span><span class="o">.</span><span class="n">albert_sep_token</span><span class="p">)</span>
    <span class="n">new_hp</span><span class="o">.</span><span class="n">set_hparam</span><span class="p">(</span><span class="s2">&quot;mask_val&quot;</span><span class="p">,</span> <span class="n">conventions</span><span class="o">.</span><span class="n">albert_mask_token</span><span class="p">)</span>

    <span class="n">new_hp</span><span class="o">.</span><span class="n">set_hparam</span><span class="p">(</span>
        <span class="s1">&#39;padding_val_id&#39;</span><span class="p">,</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">vocab</span><span class="p">[</span><span class="n">conventions</span><span class="o">.</span><span class="n">albert_padding_token</span><span class="p">])</span>
    <span class="k">assert</span> <span class="n">new_hp</span><span class="o">.</span><span class="n">padding_val_id</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;padding should be indexed as 0&quot;</span>
    <span class="n">new_hp</span><span class="o">.</span><span class="n">set_hparam</span><span class="p">(</span>
        <span class="s1">&#39;unk_val_id&#39;</span><span class="p">,</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">vocab</span><span class="p">[</span><span class="n">conventions</span><span class="o">.</span><span class="n">albert_unk_token</span><span class="p">])</span>
    <span class="n">new_hp</span><span class="o">.</span><span class="n">set_hparam</span><span class="p">(</span>
        <span class="s1">&#39;cls_val_id&#39;</span><span class="p">,</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">vocab</span><span class="p">[</span><span class="n">conventions</span><span class="o">.</span><span class="n">albert_cls_token</span><span class="p">])</span>
    <span class="n">new_hp</span><span class="o">.</span><span class="n">set_hparam</span><span class="p">(</span>
        <span class="s1">&#39;sep_val_id&#39;</span><span class="p">,</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">vocab</span><span class="p">[</span><span class="n">conventions</span><span class="o">.</span><span class="n">albert_sep_token</span><span class="p">])</span>
    <span class="n">new_hp</span><span class="o">.</span><span class="n">set_hparam</span><span class="p">(</span>
        <span class="s1">&#39;mask_val_id&#39;</span><span class="p">,</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">vocab</span><span class="p">[</span><span class="n">conventions</span><span class="o">.</span><span class="n">albert_mask_token</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">new_hp</span><span class="p">,</span> <span class="n">tokenizer</span></div>


<div class="viewcode-block" id="get_nltk_tokenizer"><a class="viewcode-back" href="../../deeptextworld.html#deeptextworld.tokenizers.get_nltk_tokenizer">[docs]</a><span class="k">def</span> <span class="nf">get_nltk_tokenizer</span><span class="p">(</span>
        <span class="n">hp</span><span class="p">:</span> <span class="n">HParams</span><span class="p">,</span> <span class="n">vocab_file</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">conventions</span><span class="o">.</span><span class="n">nltk_vocab_file</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">HParams</span><span class="p">,</span> <span class="n">Tokenizer</span><span class="p">]:</span>
    <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">NLTKTokenizer</span><span class="p">(</span><span class="n">vocab_file</span><span class="o">=</span><span class="n">vocab_file</span><span class="p">,</span> <span class="n">do_lower_case</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">new_hp</span> <span class="o">=</span> <span class="n">copy_hparams</span><span class="p">(</span><span class="n">hp</span><span class="p">)</span>
    <span class="n">new_hp</span><span class="o">.</span><span class="n">set_hparam</span><span class="p">(</span><span class="s1">&#39;vocab_size&#39;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">vocab</span><span class="p">))</span>
    <span class="n">new_hp</span><span class="o">.</span><span class="n">set_hparam</span><span class="p">(</span><span class="s2">&quot;padding_val&quot;</span><span class="p">,</span> <span class="n">conventions</span><span class="o">.</span><span class="n">nltk_padding_token</span><span class="p">)</span>
    <span class="n">new_hp</span><span class="o">.</span><span class="n">set_hparam</span><span class="p">(</span><span class="s2">&quot;unk_val&quot;</span><span class="p">,</span> <span class="n">conventions</span><span class="o">.</span><span class="n">nltk_unk_token</span><span class="p">)</span>
    <span class="n">new_hp</span><span class="o">.</span><span class="n">set_hparam</span><span class="p">(</span><span class="s2">&quot;sos&quot;</span><span class="p">,</span> <span class="n">conventions</span><span class="o">.</span><span class="n">nltk_sos_token</span><span class="p">)</span>
    <span class="n">new_hp</span><span class="o">.</span><span class="n">set_hparam</span><span class="p">(</span><span class="s2">&quot;eos&quot;</span><span class="p">,</span> <span class="n">conventions</span><span class="o">.</span><span class="n">nltk_eos_token</span><span class="p">)</span>

    <span class="n">new_hp</span><span class="o">.</span><span class="n">set_hparam</span><span class="p">(</span>
        <span class="s1">&#39;padding_val_id&#39;</span><span class="p">,</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">vocab</span><span class="p">[</span><span class="n">conventions</span><span class="o">.</span><span class="n">nltk_padding_token</span><span class="p">])</span>
    <span class="k">assert</span> <span class="n">new_hp</span><span class="o">.</span><span class="n">padding_val_id</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;padding should be indexed as 0&quot;</span>
    <span class="n">new_hp</span><span class="o">.</span><span class="n">set_hparam</span><span class="p">(</span>
        <span class="s1">&#39;unk_val_id&#39;</span><span class="p">,</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">vocab</span><span class="p">[</span><span class="n">conventions</span><span class="o">.</span><span class="n">nltk_unk_token</span><span class="p">])</span>
    <span class="n">new_hp</span><span class="o">.</span><span class="n">set_hparam</span><span class="p">(</span><span class="s1">&#39;sos_id&#39;</span><span class="p">,</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">vocab</span><span class="p">[</span><span class="n">conventions</span><span class="o">.</span><span class="n">nltk_sos_token</span><span class="p">])</span>
    <span class="n">new_hp</span><span class="o">.</span><span class="n">set_hparam</span><span class="p">(</span><span class="s1">&#39;eos_id&#39;</span><span class="p">,</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">vocab</span><span class="p">[</span><span class="n">conventions</span><span class="o">.</span><span class="n">nltk_eos_token</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">new_hp</span><span class="p">,</span> <span class="n">tokenizer</span></div>


<div class="viewcode-block" id="get_zork_tokenizer"><a class="viewcode-back" href="../../deeptextworld.html#deeptextworld.tokenizers.get_zork_tokenizer">[docs]</a><span class="k">def</span> <span class="nf">get_zork_tokenizer</span><span class="p">(</span>
        <span class="n">hp</span><span class="p">:</span> <span class="n">HParams</span><span class="p">,</span>
        <span class="n">vocab_file</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">conventions</span><span class="o">.</span><span class="n">legacy_zork_vocab_file</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">HParams</span><span class="p">,</span> <span class="n">Tokenizer</span><span class="p">]:</span>
    <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">LegacyZorkTokenizer</span><span class="p">(</span><span class="n">vocab_file</span><span class="o">=</span><span class="n">vocab_file</span><span class="p">)</span>
    <span class="n">new_hp</span> <span class="o">=</span> <span class="n">copy_hparams</span><span class="p">(</span><span class="n">hp</span><span class="p">)</span>
    <span class="n">new_hp</span><span class="o">.</span><span class="n">set_hparam</span><span class="p">(</span><span class="s1">&#39;vocab_size&#39;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">vocab</span><span class="p">))</span>
    <span class="n">new_hp</span><span class="o">.</span><span class="n">set_hparam</span><span class="p">(</span><span class="s2">&quot;padding_val&quot;</span><span class="p">,</span> <span class="n">conventions</span><span class="o">.</span><span class="n">nltk_padding_token</span><span class="p">)</span>
    <span class="n">new_hp</span><span class="o">.</span><span class="n">set_hparam</span><span class="p">(</span><span class="s2">&quot;unk_val&quot;</span><span class="p">,</span> <span class="n">conventions</span><span class="o">.</span><span class="n">nltk_unk_token</span><span class="p">)</span>
    <span class="n">new_hp</span><span class="o">.</span><span class="n">set_hparam</span><span class="p">(</span><span class="s2">&quot;sos&quot;</span><span class="p">,</span> <span class="n">conventions</span><span class="o">.</span><span class="n">nltk_sos_token</span><span class="p">)</span>
    <span class="n">new_hp</span><span class="o">.</span><span class="n">set_hparam</span><span class="p">(</span><span class="s2">&quot;eos&quot;</span><span class="p">,</span> <span class="n">conventions</span><span class="o">.</span><span class="n">nltk_eos_token</span><span class="p">)</span>

    <span class="n">new_hp</span><span class="o">.</span><span class="n">set_hparam</span><span class="p">(</span>
        <span class="s1">&#39;padding_val_id&#39;</span><span class="p">,</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">vocab</span><span class="p">[</span><span class="n">conventions</span><span class="o">.</span><span class="n">nltk_padding_token</span><span class="p">])</span>
    <span class="n">new_hp</span><span class="o">.</span><span class="n">set_hparam</span><span class="p">(</span>
        <span class="s1">&#39;unk_val_id&#39;</span><span class="p">,</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">vocab</span><span class="p">[</span><span class="n">conventions</span><span class="o">.</span><span class="n">nltk_unk_token</span><span class="p">])</span>
    <span class="n">new_hp</span><span class="o">.</span><span class="n">set_hparam</span><span class="p">(</span><span class="s1">&#39;sos_id&#39;</span><span class="p">,</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">vocab</span><span class="p">[</span><span class="n">conventions</span><span class="o">.</span><span class="n">nltk_sos_token</span><span class="p">])</span>
    <span class="n">new_hp</span><span class="o">.</span><span class="n">set_hparam</span><span class="p">(</span><span class="s1">&#39;eos_id&#39;</span><span class="p">,</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">vocab</span><span class="p">[</span><span class="n">conventions</span><span class="o">.</span><span class="n">nltk_eos_token</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">new_hp</span><span class="p">,</span> <span class="n">tokenizer</span></div>


<div class="viewcode-block" id="init_tokens"><a class="viewcode-back" href="../../deeptextworld.html#deeptextworld.tokenizers.init_tokens">[docs]</a><span class="k">def</span> <span class="nf">init_tokens</span><span class="p">(</span><span class="n">hp</span><span class="p">:</span> <span class="n">HParams</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">HParams</span><span class="p">,</span> <span class="n">Tokenizer</span><span class="p">]:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Note that BERT must use bert vocabulary.</span>
<span class="sd">    :param hp:</span>
<span class="sd">    :return:</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">hp</span><span class="o">.</span><span class="n">tokenizer_type</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="o">==</span> <span class="s2">&quot;bert&quot;</span><span class="p">:</span>
        <span class="n">new_hp</span><span class="p">,</span> <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">get_bert_tokenizer</span><span class="p">(</span><span class="n">hp</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">hp</span><span class="o">.</span><span class="n">tokenizer_type</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="o">==</span> <span class="s2">&quot;albert&quot;</span><span class="p">:</span>
        <span class="n">new_hp</span><span class="p">,</span> <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">get_albert_tokenizer</span><span class="p">(</span><span class="n">hp</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">hp</span><span class="o">.</span><span class="n">tokenizer_type</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="o">==</span> <span class="s2">&quot;nltk&quot;</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">hp</span><span class="o">.</span><span class="n">use_glove_emb</span><span class="p">:</span>
            <span class="c1"># the glove vocab file has been modified to have special tokens</span>
            <span class="c1"># i.e. [PAD] [UNK] &lt;S&gt; &lt;/S&gt;</span>
            <span class="n">new_hp</span><span class="p">,</span> <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">get_nltk_tokenizer</span><span class="p">(</span>
                <span class="n">hp</span><span class="p">,</span> <span class="n">vocab_file</span><span class="o">=</span><span class="n">conventions</span><span class="o">.</span><span class="n">glove_vocab_file</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">new_hp</span><span class="p">,</span> <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">get_nltk_tokenizer</span><span class="p">(</span><span class="n">hp</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">hp</span><span class="o">.</span><span class="n">tokenizer_type</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="o">==</span> <span class="s2">&quot;zork&quot;</span><span class="p">:</span>
        <span class="n">new_hp</span><span class="p">,</span> <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">get_zork_tokenizer</span><span class="p">(</span><span class="n">hp</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="s2">&quot;Unknown tokenizer type: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">hp</span><span class="o">.</span><span class="n">tokenizer_type</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">new_hp</span><span class="p">,</span> <span class="n">tokenizer</span></div>
</pre></div>

          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="../../index.html">deep-textworld</a></h1>








<h3>Navigation</h3>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../../index.html">Documentation overview</a><ul>
  <li><a href="../index.html">Module code</a><ul>
  </ul></li>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" />
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>$('#searchbox').show(0);</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2020, Xusen Yin.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 3.2.1</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.12</a>
      
    </div>

    

    
  </body>
</html>